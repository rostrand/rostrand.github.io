<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html lang="en" xmlns="http://www.w3.org/1999/xhtml">
<head>

<title>Current Research Projects</title>

<meta property='og:site_name' content='Rachel Ostrand'/>
<meta property='og:title' content='Research' />

<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <!--[if lt IE 7.]><script defer type="text/javascript" src="/files/theme/pngfix.js"></script><![endif]-->


<link rel='stylesheet' href='common.css' type='text/css' />
<link rel='stylesheet' type='text/css' href='common.css' title='weebly-theme-css' />
<style type='text/css'>


#wsite-content div.paragraph, #wsite-content p, #wsite-content .product-description, .blog-sidebar div.paragraph, .blog-sidebar p, .wsite-form-field label, .wsite-form-field label {}
#wsite-content h2, #wsite-content .product-title, .blog-sidebar h2{}
#wsite-title{font-size:38px !important;}
#wsite-content a:link, .blog-sidebar a:link{color:#3333FF !important;}
#wsite-content a:visited, .blog-sidebar a:visited{color:#3333FF !important;}
#wsite-content a:hover, .blog-sidebar a:hover{color:#990000 !important;}
</style>
<script type='text/javascript'><!--
var STATIC_BASE = 'http://cdn1.editmysite.com/';
var STYLE_PREFIX = 'wsite';
//-->
</script>




<script type='text/javascript' src='http://cdn1.editmysite.com/libraries/prototype/1.7-custom/prototype.min.js'></script>
<script type='text/javascript' src='http://cdn1.editmysite.com/libraries/scriptaculous/1.9.0-custom/effects.min.js'></script>
<script type='text/javascript' src='http://cdn1.editmysite.com/editor/images/common/utilities.js?5'></script>
<script type='text/javascript' src='http://cdn1.editmysite.com/editor/images/common/lightbox202.js?9'></script>
<script type='text/javascript' src='http://cdn1.editmysite.com/editor/libraries/flyout_menus.js?13'></script>
<script type='text/javascript'><!--
var DISABLE_NAV_MORE=1;
function initFlyouts(){initPublishedFlyoutMenus([{"id":"214724062316857364","title":"Home","url":"index.html"},{"id":"522058838173370173","title":"Resume","url":"resume.html"},{"id":"970125673552384327","title":"Research","url":"research.html"},{"id":"144715486253897019","title":"Publications & Presentations","url":"presentations.html"}],'970125673552384327',"<li class='wsite-nav-more'><a href=\"#\">more...<\/a><\/li>",'active',false)}
if (Prototype.Browser.IE) window.onload=initFlyouts; else document.observe('dom:loaded', initFlyouts);
//-->
</script>

<!---- GOOGLE ANALYTICS ---->

<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-27337603-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>



</head>

<body class='wsite-page-research'>

<!--                  navigation                  -->

<ul id="nav"><li><a href="/index.html">Home</a></li>

<li><a href="/RachelOstrand-Resume.pdf">Resume</a></li>

<li id="active"><a href="/research.html">Research</a></li>

<li><a href="/publications.html">Publications</a></li>

<li><a href="/presentations.html">Presentations</a></li>
	
 </ul>


    <!--                  main title                  -->

    <h1 id="title"><span>Current Research Projects</span></h1>


<!--                beginning of actual page             -->


<div id="wrapper">
<div class="content">
<div id='wsite-content' class='wsite-not-footer'>
<div class='wsite-not-footer'>


<h2  style=" text-align: left; ">Using speech production to detect cognitive decline and dementia progression</h2>
<h3  style=" text-align: left; ">Experiment names: Talk of Life, Circle of Life</h3><br />
<div  class="paragraph editable-text" style=" text-align: left; display: block; ">

Language is an extremely rich signal and is highly variable between different speakers, and can be diagnostic of a speaker's underlying cognitive status. This line of research investigates the characteristics of speech production (e.g., the types of words produced, speech rate, use of filler words, etc.) that are measurably affected in Alzheimer's disease, other dementias, and cognitive decline - and how speech production changes over time with the progression of the disease. In particular, this research focuses on developing automated tools for the calculation of lexical-semantic features of speech to identify early stages of cognitive decline. We are investigating speech as a diagnostic marker both cross-sectionally, to try to detect people with different degrees of impairment, as well as longitudinally, to use current speech production to predict future degree of impairment. Ultimately, understanding how language production changes over the course of a progressive disease will allow us to use linguistic measures as a diagnostic tool to supplement existing clinical tools.
<br />

<br /><strong>Collaborators: </strong>
<a href="https://www.kent.edu/psychology/profile/john-gunstad" target="_blank">John Gunstad</a> (Kent State University),
<a href="https://www.cumc.columbia.edu/adrc/profile/ambrickman" target="_blank">Adam Brickman</a> (Columbia), 
<a href="https://wp.nyu.edu/neurolinglab/people/lab-members/graham-flick/" target="_blank">Graham Flick</a> (NYU - graduate student intern), 
<a href="https://katchia.com/" target="_blank">Kat Chia</a> (Florida State University - graduate student intern)

<br />
<br /><strong>Publications: </strong>
<ul>
<li><u>Using Automatic Assessment of Speech Production to Predict Current and Future Cognitive Function in Older Adults</u> <a href="/~rostrand/Ostrand_Gunstad.2021-JGPN.pdf">(Ostrand & Gunstad, 2021)</a></li>
<li><u>Automated Assessment of Speech Production and Prediction of MCI in Older Adults</u> <a href="/~rostrand/Sanborn.etal.2021-AppliedNeuro_Adult.pdf">(Sanborn, Ostrand, Ciesla, & Gunstad, 2022)</a></li>
<li><u>Lexical Speech Features of Spontaneous Speech in Older Persons With and Without Cognitive Impairment: Reliability Analysis</u> <a href="/~rostrand/Hamrick.etal.2023-JMIR_Aging.pdf">(Hamrick, Sanborn, Ostrand, & Gunstad, 2023)</a></li>
</li>
</ul>
<br />

<strong>Grant Support:</strong>
<ul>
<li>
<a href="https://reporter.nih.gov/project-details/10641788" target="_blank">Center for Research and Education on Aging and Technology Enhancement - CREATE: Technology Support for Cognition and Social Engagement for Aging Adults with Mild Cognitive Impairment (MCI)</a> 
<u>NIH P01 (National Institute of Aging).</u> <em>Role: Consultant.</em></li>

<li>
<a href="https://reporter.nih.gov/project-details/10089378" target="_blank">Spontaneous Speech and Health Disparities in Risk of Cognitive Decline: WHICAP Offspring Ancillary Study</a> <u>NIH R01 (National Institute of Aging).</u> <em>Role: Co-PI.</em></li>

<li>
<a href="https://case.edu/medicine/cbhi/about-us/scholars" target="_blank">Using automated speech analysis to predict cognitive decline and future Alzheimer's Disease</a> <u>Cleveland Brain Health Initiative Scholars Grant.</u> <em>Role: Co-PI.</em></li>
</ul>
<br /><br /></div>


<h2  style=" text-align: left; ">Partner-specificity of linguistic alignment</h2>
<h3 style=" text-align: left; ">Experiment names: Sole Train, Have You Ever Seen The Train?, Train Train Go Away, I Can See Clearly Now (The Train Is Gone), Train in Spain, Talk Like an Egyptian, Rachel-Squared, Synpacts, Talking Care of Business</h3><br />
<div  class="paragraph editable-text" style=" text-align: left; display: block; ">
This area of research investigates statistical language learning and contextual adaptation within dialogue and conversation. A person's speech production can be affected by many aspects of the linguistic context, including recent linguistic experience, personal linguistic preferences, and characteristics of their listener. In particular, speakers adapt many properties of their speech to match those properties produced by their conversational partners, a process known as <em>alignment</em>. Do speakers learn - and align to - a partner's linguistic preferences on an individual basis, or do they adapt to the overall linguistic environment in a partner-independent way? For example, does a listener learn that a speaker, when given a choice, will use one syntactic structure over another, or does a listener's syntactic system just adapt to recent events regardless of speaker identity?
<br /><br /><strong>Collaborators: </strong>
<a href="http://www.psychology.ucsd.edu/people/profiles/vferreira.html">Vic Ferreira</a> (UCSD), 
<a href="https://sites.google.com/view/languageandcommunicationlab/home">Iva Ivanova</a> (UT El Paso), 
<a href="https://raryskin.github.io/">Rachel Ryskin</a> (UC Merced),
<a href="https://www.eleanorchodroff.com/">Eleanor Chodroff</a> (University of York)

<br />
<br /><strong>Publications: </strong>
<ul>
<li><u>Rapid Lexical Alignment to a Conversational Agent.</u> <a href="/~rostrand/Ostrand.etal.2023-Interspeech_Proceedings.pdf">(Ostrand, Ferreira, & Piorkowski, 2023)</a></li>

<li><u>Learning speaker-specific structural expectations</u> <a href="https://osf.io/w2msz/?view_only=7bebcc238d8846bf872671c48fca1084">(Ostrand & Ryskin, Stage 1 Registered Report)</a></li>

<li><u>It's alignment all the way down, but not all the way up: Speakers align on some features but not others within a dialogue</u> <a href="/~rostrand/Ostrand_Chodroff.2021-JPhon.pdf">(Ostrand & Chodroff, 2021)</a></li>

<li><u>Repeat after us: Syntactic alignment is not partner-specific</u> <a href="/~rostrand/Ostrand_Ferreira.2019-JML.pdf">(Ostrand & Ferreira, 2019)</a></li>

<li><u>Syntactic entrainment: The repetition of syntactic structures in event descriptions</u> <a href="/~rostrand/Gruberg.etal.2019-JML.pdf">(Gruberg, Ostrand, Momma, & Ferreira, 2019)</a></li>
</ul>


<br /><br /></div>



<h2  style=" text-align: left; ">The time course of audio-visual integration in language processing<br /></h2>

<h3  style=" text-align: left; ">Experiment names: Lips Don't Lie</h3><br />

<div  class="paragraph editable-text" style=" text-align: left; display: block; ">
In face-to-face speech, listeners receive both an auditory and a visual stream from their conversational partner. These two modalities necessarily enter the brain separately, but eventually are integrated so that the listener experiences a single, unified speech percept. This line of research investigates the time course and mechanisms behind this multi-sensory integration.  Does this integration happen before or after lexical access? Which signal is sent to the lexicon for lexical access: the unimodal auditory signal or the integrated audio-visual percept?

<br />
<br /><strong>Collaborators: </strong>
<a href="http://www.brown.edu/research/labs/blumstein/">Sheila Blumstein</a> (Brown),
<a href="https://www.brown.edu/academics/cognitive-linguistic-psychological-sciences/people/faculty/james-morgan">Jim Morgan</a> (Brown),
<a href="http://www.psychology.ucsd.edu/people/profiles/vferreira.html">Vic Ferreira</a> (UCSD)
<br />

<br /><strong>Publications:</strong>
<ul>

<li><u>Semantic Priming from McGurk words: Priming depends on perception.</u> 
<a href="/~rostrand/Dorsi.etal.2023-APP.pdf">
(Dorsi, Ostrand, & Rosenblum, 2023)</a></li>

<li><u>What you see isn't always what you get: Auditory word signals trump consciously perceived words in lexical access</u> 
<a href="/~rostrand/Ostrand.etal.2016-Cognition.pdf">
(Ostrand, Blumstein, Ferreira, & Morgan, 2016)</a></li>

<li><u>When Hearing Lips and Seeing Voices Becomes Perceiving Speech: Auditory-Visual Integration in Lexical Access</u> 
<a href="/~rostrand/Ostrand.etal.2011-CogSci_Proceedings.pdf">(Ostrand, Blumstein, & Morgan, 2011)</a></li>
</ul>
</br>


<h2  style=" text-align: left; ">Changes in speech production to detect cognitive states<br /></h2>
<div  class="paragraph editable-text" style=" text-align: left; display: block; ">

Speech production may reflect cognitive changes induced by a number of mental health disorders, neurodegenerative diseases, and external states. In collaboration with many colleagues, I am involved in several exploratory projects investigating the use of linguistic markers to detect cognitive states including Parkinson's disease medication state and drug use.
<br />
<br /><strong>Collaborators: </strong>
<a href="https://researcher.watson.ibm.com/researcher/view.php?person=us-gcecchi">Guillermo Cecchi</a> (IBM Research), 
<a href="https://researcher.watson.ibm.com/researcher/view.php?person=us-rnorel">Kely Norel</a> (IBM Research),
<a href="https://researcher.watson.ibm.com/researcher/view_person_pubs.php?person=ibm-Carla.Agurto">Carla Agurto</a> (IBM Research)
<br />

<br /><strong>Publications:</strong>
<ul>

<li><u>Automated computer vision assessment of hypomimia in Parkinson's disease</u>
<a href="/~rostrand/Abrami.etal.2021-JMIR.pdf">(Abrami et al., 2021)</a></li>

<li><u>Detection of Acute 3,4-Methylenedioxymethamphetamine (MDMA) Effects Across Protocols Using Automated Natural Language Processing</u>
<a href="/~rostrand/Agurto.etal.2020-Neuropsychopharmacology.pdf">(Agurto et al., 2020)</a></li>

<li><u>Phonological markers of Oxytocin and MDMA ingestion</u>
<a href="https://www.isca-speech.org/archive/Interspeech_2017/abstracts/0621.html">(Agurto et al., 2017)</a></li>
</ul>
</div>


<CENTER>

<br /><br /><br />
<font size="1">
Last updated: October 18, 2023

</CENTER>


</div>
</div>
</div>
</div>



     <!--                  footer                  -->


<div id="footer">
<span><span>
<style type='text/css'></style>

<!--

<script type='text/javascript'>

</script>
</span></span>
</div></div>
 -->

<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-7870337-1']);
  _gaq.push(['_setDomainName', 'none']);
  _gaq.push(['_setAllowLinker', true]);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

<!-- Start Quantcast tag -->
<script type="text/javascript">
  _qoptions={
    qacct:"p-0dYLvhSGGqUWo"
  };
</script>
<script type="text/javascript" src="http://edge.quantserve.com/quant.js"></script>
<noscript>
<img src="http://pixel.quantserve.com/pixel/p-0dYLvhSGGqUWo.gif" style="display: none;" border="0" height="1" width="1" alt="Quantcast"/>
</noscript>
<!-- End Quantcast tag -->


</body>
</html>